{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6daf3908",
   "metadata": {},
   "source": [
    "This project focuses on data transformation, dimensionality reduction and calculating distance matrices using different transformation techniques. The dataset is normalized and its Eucledian distance is calculated between all the rows. Similarly, the Haar Wavelet Transformation is applied to row normalized data and its Euclediamn distance is calculated. On the other hand, we also apply PCA transformation to column normalized data and then its Eucledian distance is also calculated. At the end, we comapre three Eucledian distance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:44:31.148389Z",
     "start_time": "2024-09-19T20:44:31.143225Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data manipulation, numerical calculation, and random operations. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc2bc9bb95684938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:44:36.064885Z",
     "start_time": "2024-09-19T20:44:35.821538Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv('../data/Asgmnt1_data.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2014daf6281ee5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:44:46.835915Z",
     "start_time": "2024-09-19T20:44:42.967614Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizing the data by row\n",
    "normalized_rows = []\n",
    "number_rows = df.shape[0]\n",
    "\n",
    "for i in range(number_rows):\n",
    "    normalized_row = []\n",
    "    row_values = df.iloc[i, :]\n",
    "    \n",
    "    mean = row_values.mean()\n",
    "    std = row_values.std(ddof=1)\n",
    "    \n",
    "    for val in row_values:\n",
    "        normalized_val = (val - mean) / std\n",
    "        normalized_row.append(normalized_val)\n",
    "        \n",
    "    normalized_rows.append(pd.Series(normalized_row, index=df.columns, name=df.index[i]))\n",
    "    \n",
    "normalized_data = pd.concat(normalized_rows, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0e5f7602ec042b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:45:19.352470Z",
     "start_time": "2024-09-19T20:45:19.343789Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to calculate the Euclidean distance between two rows\n",
    "def calculate_euclidean_distance(row1, row2):\n",
    "    sum_square = 0\n",
    "    for (val1, val2) in zip(row1, row2):\n",
    "        sum_square += (val1 - val2) ** 2\n",
    "    \n",
    "    return math.sqrt(sum_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b541d3f7d4795c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:45:20.289091Z",
     "start_time": "2024-09-19T20:45:20.284144Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to construct a Euclidean distance matrix from a DataFrame\n",
    "def construct_euclidean_distance_matrix(dataframe):\n",
    "    n = dataframe.shape[0]\n",
    "    distance_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            distance = calculate_euclidean_distance(dataframe.iloc[i], dataframe.iloc[j])\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "    \n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcd30d652095c5c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-19T20:45:21.657113Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Constructing a Euclidean distance matrix from the normalized data\n",
    "normalized_distance_matrix = construct_euclidean_distance_matrix(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afceece7d0cedc6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-19T20:10:54.863168Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to create a Haar non-square matrix for transformation (used in wavelet transformations)\n",
    "def haar_non_square_matrix(m, n):\n",
    "    if n < m:\n",
    "        raise ValueError(\"Number of columns must be greater than or equal to the number of rows\")\n",
    "    \n",
    "    H = np.zeros((m, n))\n",
    "\n",
    "    # First row is all ones\n",
    "    H[0, :] = 1 / np.sqrt(n)\n",
    "    \n",
    "    # Build the rest of the matrix\n",
    "    for level in range(1, m):\n",
    "        step = n // (2 ** level)\n",
    "        if step == 0:\n",
    "            break  # Stop if the step becomes zero (more rows than meaningful steps)\n",
    "        \n",
    "        for i in range(0, n, 2 * step):\n",
    "            H[level, i:i + step] = 1 / np.sqrt(step)\n",
    "            H[level, i + step:i + 2 * step] = -1 / np.sqrt(step)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fcb79c3e459d8d8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Haar Wavelet Matrix for wavelet transofrmation\n",
    "h = haar_non_square_matrix(128, 16000).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eeac1ae977f1000",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply the data with haar wavelet matrix\n",
    "wavelet_transformed_normalized_data = normalized_data * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c63a4b88e06b67",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-19T20:10:54.868758Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavelet_transformed_distance_matrix = construct_euclidean_distance_matrix(wavelet_transformed_normalized_data.iloc[:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f59663",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('wavelet_transformed_distance_matrix.csv', wavelet_transformed_distance_matrix, delimiter=',', fmt='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb141fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data by column\n",
    "normalized_columns = []\n",
    "\n",
    "# Get the number of columns\n",
    "number_columns = df.shape[1]\n",
    "\n",
    "# Loop through each column to normalize\n",
    "for col in df.columns:\n",
    "    normalized_column = []\n",
    "    column_values = df[col]\n",
    "    \n",
    "    mean = column_values.mean()\n",
    "    std = column_values.std(ddof=1)\n",
    "    \n",
    "    # Normalize each value in the column\n",
    "    for val in column_values:\n",
    "        normalized_val = (val - mean) / std\n",
    "        normalized_column.append(normalized_val)\n",
    "    \n",
    "    normalized_columns.append(pd.Series(normalized_column, index=df.index, name=col))\n",
    "\n",
    "# Concatenate the normalized columns to form the normalized DataFrame\n",
    "column_normalized_data = pd.concat(normalized_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9016126ab8639f73",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-19T20:10:54.870963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform Principal Component Analysis (PCA) on the normalized data\n",
    "def PCA(data_before_pca, n_principal_components):\n",
    "    covariance_matrix = (data_before_pca.T @ data_before_pca)\n",
    "    # np.cov(data_before_pca, rowvar=False)\n",
    "\n",
    "    # Calculate eigenvalues and eigenvectors of the covariance matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # Sort eigenvalues and corresponding eigenvectors in descending order of eigenvalues\n",
    "    components = eigenvectors[:, [127, 126, 125, 124]]\n",
    "    \n",
    "    data_after_pca = np.dot(data_before_pca, components)\n",
    "    \n",
    "    return data_after_pca, eigenvectors[:n_principal_components] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb8d88aef9defac",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-19T20:10:54.873137Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pca_transformed_data, top_eigenvalues = PCA(normalized_data, 4)\n",
    "pca_transformed_data, top_eigenvalues = PCA(column_normalized_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9950315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_transformed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d0897cfe0105a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct a Euclidean distance matrix from the PCA-transformed data\n",
    "pca_transformed_distance_matrix = construct_euclidean_distance_matrix(pd.DataFrame(pca_transformed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b3a8b701bec6311a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:39:47.604201Z",
     "start_time": "2024-09-19T20:39:47.595833Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to generate two pairs of random indices from the matrix\n",
    "def generate_random_pairs(matrix_size):\n",
    "    row1, col1, row2, col2 = -1, -2, -1, -2\n",
    "    \n",
    "    while (row1 == row2 and col1 == col2) or (row1 == col1 and row2 == col1):\n",
    "        row1, col1 = random.randint(0, matrix_size-1), random.randint(0, matrix_size-1)\n",
    "        row2, col2 = random.randint(0, matrix_size-1), random.randint(0, matrix_size-1)\n",
    "    return (row1, col1), (row2, col2)\n",
    "\n",
    "def compare_cells(cell1, cell2):\n",
    "    if cell1 > cell2:\n",
    "        return 'greater'\n",
    "    elif cell1 == cell2:\n",
    "        return 'equal'\n",
    "    else:\n",
    "        return 'smaller'\n",
    "    \n",
    "# Function to compare random cells across three matrices\n",
    "def compare_random_cells(matrix_list1, matrix_list2, matrix_list3, n):\n",
    "    matrix_size = len(matrix_list1[0])  # Assuming all matrices are the same size\n",
    "    count = 0  # Counter for matches across all matrices\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Generate random pairs of indices\n",
    "        pair1, pair2 = generate_random_pairs(matrix_size)\n",
    "        \n",
    "        # Extract cell values from each matrix\n",
    "        matrix1_cell1 = matrix_list1[pair1[0]][pair1[1]]\n",
    "        matrix1_cell2 = matrix_list1[pair2[0]][pair2[1]]\n",
    "        \n",
    "        matrix2_cell1 = matrix_list2[pair1[0]][pair1[1]]\n",
    "        matrix2_cell2 = matrix_list2[pair2[0]][pair2[1]]\n",
    "        \n",
    "        matrix3_cell1 = matrix_list3[pair1[0]][pair1[1]]\n",
    "        matrix3_cell2 = matrix_list3[pair2[0]][pair2[1]]\n",
    "\n",
    "        \n",
    "        # Compare cells in each matrix\n",
    "        comparison1 = compare_cells(matrix1_cell1, matrix1_cell2)\n",
    "        comparison2 = compare_cells(matrix2_cell1, matrix2_cell2)\n",
    "        comparison3 = compare_cells(matrix3_cell1, matrix3_cell2)\n",
    "        \n",
    "        # Check if all comparisons are the same\n",
    "        if comparison1 == comparison2 == comparison3:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "53c7aa8944ce0c70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T20:44:13.976529Z",
     "start_time": "2024-09-19T20:44:12.931643Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n= 100\n",
    "count = compare_random_cells(normalized_distance_matrix, wavelet_transformed_distance_matrix, pca_transformed_distance_matrix, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d50d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
